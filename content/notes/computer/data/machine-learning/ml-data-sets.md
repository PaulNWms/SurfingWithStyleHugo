---
title: ML Data Sets
description: 
date: 2023-11-26T06:59:00Z
keywords: 
draft: false
tags:
---
To see how well a model will generalize to new cases, the data is split into a training set, a test set and a validation set.

It is common to use 80% of the data for training and hold out 20% for testing.

In cross-validation, a validation set is randomly held out from the training set during training.

The No Free Lunch Theorem states that there is no model that is guaranteed to work best on a given dataset.  The only way to know for sure is to evaluate them all.

---
# References

- [The Unreasonable Effectiveness of Data (googleusercontent.com)](http://static.googleusercontent.com/media/research.google.com/fr//pubs/archive/35179.pdf)
- [The Lack of A Priori Distinctions Between Learning Algorithms - Google Scholar](https://scholar.google.fr/scholar?q=lack+of+a+priori+distinctions+between+learning+algorithms)

- [UCI Machine Learning Repository](https://archive.ics.uci.edu/)
- [Kaggle](https://www.kaggle.com/datasets)
- [AWS](https://registry.opendata.aws/)
- [Data Portals](https://dataportals.org/)
- [Open Data Monitor](https://opendatamonitor.eu)
- [Retail Trading Activity Tracker: Keep track of retail sentiment (nasdaq.com)](https://data.nasdaq.com/institutional-investors)
- [Wikipedia](https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research)
- [Where can I find large datasets open to the public? - Quora](https://www.quora.com/Where-can-I-find-large-datasets-open-to-the-public)
- [Datasets (reddit.com)](https://www.reddit.com/r/datasets/)
