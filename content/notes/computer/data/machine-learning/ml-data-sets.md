---
title: ML Data Sets
description: 
date: 2023-11-26T06:59
keywords: 
draft: false
tags:
---
To see how well a model will generalize to new cases, the data is split into a training set, a test set and a validation set.

It is common to use 80% of the data for training and hold out 20% for testing.

In cross-validation, a validation set is randomly held out from the training set during training.

The No Free Lunch Theorem states that there is no model that is guaranteed to work best on a given dataset.  The only way to know for sure is to evaluate them all.

---
# References

- [The Unreasonable Effectiveness of Data (googleusercontent.com)](http://static.googleusercontent.com/media/research.google.com/fr//pubs/archive/35179.pdf)
- [The Lack of A Priori Distinctions Between Learning Algorithms - Google Scholar](https://scholar.google.fr/scholar?q=lack+of+a+priori+distinctions+between+learning+algorithms)
